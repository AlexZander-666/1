2025-12-18 17:58:34,307 - INFO - Logging initialized. Output directory: outputs/lite_amsnet_quickstart
2025-12-18 17:58:35,505 - INFO - Optimized Config: {'dataset': 'sisfall', 'data_root': './data', 'out_dir': 'outputs/lite_amsnet_quickstart', 'model': 'liteams', 'epochs': 50, 'batch_size': 64, 'lr': 0.001, 'warmup_epochs': 5, 'accum_steps': 1, 'channels': 248, 'n_blocks': 8, 'kernel_sizes': [7, 15, 31, 63], 'freq_method': 'fft', 'fusion_variant': 'enhanced', 'fusion_kernel_sizes': (3, 5, 7), 'num_bands': 4, 'band_edges': None, 'adaptive_bands': True, 'attn_time': 'none', 'attn_freq': 'none', 'attn_fuse': 'none', 'attn_lite': 'none', 'faa_axis_attn': True, 'num_workers': 0, 'num_classes': 2, 'in_channels': 3, 'patience': 15, 'window_size': 512, 'stride': 256, 'channels_used': 'accel3', 'augment': False, 'noise_std': 0.05, 'scale_range': [0.9, 1.1], 'time_shift_ratio': 0.1, 'drop_prob': 0.1, 'eval_mode': 'loso', 'seeds': [42], 'amp': False, 'weighted_loss': False, 'profile': False, 'run_robustness': False, 'run_ablation_suite': False, 'allow_metrics_fallback': False, 'viz_tsne': False, 'viz_tsne_stage': 'final', 'viz_routing': False, 'viz_gradcam': False, 'loso_max_folds': 1, 'deterministic': False, 'use_tfcl': False, 'ablation': {'mspa': True, 'dks': True, 'faa': True, 'tfcl': True, 'center': True}, 'proj_dim': 128, 'tf_temperature': 0.1, 'tf_supervised_weight': 0.1, 'tf_cross_weight': 0.3, 'tf_hierarchical': True, 'label_smoothing': 0.0, 'min_patience': 5, 'patience_decay': 0.9, 'loss_alpha': 0.1, 'loss_beta': 0.01, 'rocket_kernels': 256, 'rocket_kernel_size': 9, 'lstm_hidden': 128, 'stat_baseline': None, 'sample_rate': 50.0, 'cross_eval': False, 'resume': None}
2025-12-18 17:58:35,509 - INFO - Seed set to 42 (deterministic=False)
2025-12-18 17:58:35,530 - INFO - Running LOSO across 12 subjects.
2025-12-18 17:59:40,394 - INFO - [loso_SA01] Model: liteams
2025-12-18 17:59:40,394 - INFO - [loso_SA01]   Total params: 1.03M
2025-12-18 17:59:40,394 - INFO - [loso_SA01]   Trainable params: 1.03M
2025-12-18 17:59:43,658 - INFO - [loso_SA01] Starting training: epochs=50, batch_size=64, num_workers=0, train_samples=14446
2025-12-18 18:01:07,752 - INFO - Logging initialized. Output directory: outputs/lite_amsnet_quickstart
2025-12-18 18:01:10,767 - INFO - Optimized Config: {'dataset': 'sisfall', 'data_root': './data', 'out_dir': 'outputs/lite_amsnet_quickstart', 'model': 'liteams', 'epochs': 50, 'batch_size': 64, 'lr': 0.001, 'warmup_epochs': 5, 'accum_steps': 1, 'channels': 248, 'n_blocks': 8, 'kernel_sizes': [7, 15, 31, 63], 'freq_method': 'fft', 'fusion_variant': 'enhanced', 'fusion_kernel_sizes': (3, 5, 7), 'num_bands': 4, 'band_edges': None, 'adaptive_bands': True, 'attn_time': 'none', 'attn_freq': 'none', 'attn_fuse': 'none', 'attn_lite': 'none', 'faa_axis_attn': True, 'num_workers': 0, 'num_classes': 2, 'in_channels': 3, 'patience': 15, 'window_size': 512, 'stride': 256, 'channels_used': 'accel3', 'augment': False, 'noise_std': 0.05, 'scale_range': [0.9, 1.1], 'time_shift_ratio': 0.1, 'drop_prob': 0.1, 'eval_mode': 'loso', 'seeds': [42], 'amp': False, 'weighted_loss': False, 'profile': False, 'run_robustness': False, 'run_ablation_suite': False, 'allow_metrics_fallback': False, 'viz_tsne': False, 'viz_tsne_stage': 'final', 'viz_routing': False, 'viz_gradcam': False, 'loso_max_folds': 1, 'deterministic': False, 'use_tfcl': False, 'ablation': {'mspa': True, 'dks': True, 'faa': True, 'tfcl': True, 'center': True}, 'proj_dim': 128, 'tf_temperature': 0.1, 'tf_supervised_weight': 0.1, 'tf_cross_weight': 0.3, 'tf_hierarchical': True, 'label_smoothing': 0.0, 'min_patience': 5, 'patience_decay': 0.9, 'loss_alpha': 0.1, 'loss_beta': 0.01, 'rocket_kernels': 256, 'rocket_kernel_size': 9, 'lstm_hidden': 128, 'stat_baseline': None, 'sample_rate': 50.0, 'cross_eval': False, 'resume': None}
2025-12-18 18:01:10,778 - INFO - Seed set to 42 (deterministic=False)
2025-12-18 18:01:10,808 - INFO - Running LOSO across 12 subjects.
2025-12-18 18:02:45,653 - INFO - [loso_SA01] Model: liteams
2025-12-18 18:02:45,654 - INFO - [loso_SA01]   Total params: 1.03M
2025-12-18 18:02:45,654 - INFO - [loso_SA01]   Trainable params: 1.03M
2025-12-18 18:02:52,336 - INFO - [loso_SA01] Starting training: epochs=50, batch_size=64, num_workers=0, train_samples=14446
2025-12-18 18:18:38,586 - ERROR - Run failed for seed 42: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4428672 bytes.
2025-12-18 18:18:38,597 - ERROR - Traceback (most recent call last):
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 2795, in main
    res = run_one_experiment(config, s, args.resume)
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 2591, in run_one_experiment
    res = train_eval_split(train_ds, val_ds, test_ds, split_tag, resume_path_split)
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 2402, in train_eval_split
    loss, loss_parts = train_epoch(model, train_dl, optimizer, device, criterion, scaler, config['accum_steps'])
                       ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 1225, in train_epoch
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "C:\Python314\Lib\site-packages\torch\_tensor.py", line 625, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Python314\Lib\site-packages\torch\autograd\__init__.py", line 354, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Python314\Lib\site-packages\torch\autograd\graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
RuntimeError: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4428672 bytes.

2025-12-18 18:18:38,682 - INFO - Final Summary: {}
2025-12-18 18:18:39,424 - ERROR - Run failed for seed 42: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4428672 bytes.
2025-12-18 18:18:39,429 - ERROR - Traceback (most recent call last):
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 2795, in main
    res = run_one_experiment(config, s, args.resume)
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 2591, in run_one_experiment
    res = train_eval_split(train_ds, val_ds, test_ds, split_tag, resume_path_split)
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 2402, in train_eval_split
    loss, loss_parts = train_epoch(model, train_dl, optimizer, device, criterion, scaler, config['accum_steps'])
                       ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\SCI666\code\PhyCL-Net_experiments.py", line 1225, in train_epoch
    loss.backward()
    ~~~~~~~~~~~~~^^
  File "C:\Python314\Lib\site-packages\torch\_tensor.py", line 625, in backward
    torch.autograd.backward(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        self, gradient, retain_graph, create_graph, inputs=inputs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Python314\Lib\site-packages\torch\autograd\__init__.py", line 354, in backward
    _engine_run_backward(
    ~~~~~~~~~~~~~~~~~~~~^
        tensors,
        ^^^^^^^^
    ...<5 lines>...
        accumulate_grad=True,
        ^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Python314\Lib\site-packages\torch\autograd\graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        t_outputs, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )  # Calls into the C++ engine to run the backward pass
    ^
RuntimeError: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4428672 bytes.

2025-12-18 18:18:39,483 - INFO - Final Summary: {}
